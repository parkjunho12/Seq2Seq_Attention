{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "Nt432JiJgboz",
    "outputId": "df4c9ae6-9df1-4a6d-f240-5123f887bd9d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\parkjunho\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From <ipython-input-1-7d5ce81e8e3d>:54: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-7d5ce81e8e3d>:58: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\parkjunho\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\parkjunho\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch: 0400 cost = 0.000075\n",
      "Epoch: 0800 cost = 0.000000\n",
      "Epoch: 1200 cost = 0.000000\n",
      "Epoch: 1600 cost = 0.000013\n",
      "Epoch: 2000 cost = 0.000000\n",
      "['Il', \"y'a\", 'une', 'pomme', 'P'] -> ['i', 'am', 'a', 'student', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code by Tae Hwan Jung(Jeff Jung) @graykode\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = [\"Il y'a une pomme P\", \"S i am a student\", \"i am a student E\"]\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# Parameter\n",
    "n_step = 5  # maxium number of words in one sentence(=number of time steps)\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "    return input_batch, output_batch, target_batch\n",
    "\n",
    "# Model\n",
    "#enc_inputs = tf.placeholder(tf.float32, [None, None, n_class])  # [batch_size, n_step, n_class]\n",
    "#dec_inputs = tf.placeholder(tf.float32, [None, None, n_class])  # [batch_size, n_step, n_class]\n",
    "#targets = tf.placeholder(tf.int64, [1, n_step])  # [batch_size, n_step], not one-hot\n",
    "\n",
    "# Linear for attention\n",
    "attn = tf.Variable(\"attn\", tf.random_normal([n_hidden, n_hidden]))\n",
    "out = tf.Variable(\"out\", tf.random_normal([n_hidden * 2, n_class]))\n",
    "\n",
    "def get_att_score(dec_output, enc_output):  # enc_output [n_step, n_hidden]\n",
    "    score = tf.squeeze(tf.matmul(enc_output, attn), 0)  # score : [n_hidden]\n",
    "    dec_output = tf.squeeze(dec_output, [0, 1])  # dec_output : [n_hidden]\n",
    "    return tf.tensordot(dec_output, score, 1)  # inner product make scalar value\n",
    "\n",
    "def get_att_weight(dec_output, enc_outputs):\n",
    "    attn_scores = []  # list of attention scalar : [n_step]\n",
    "    enc_outputs = tf.transpose(enc_outputs, [1, 0, 2])  # enc_outputs : [n_step, batch_size, n_hidden]\n",
    "    for i in range(n_step):\n",
    "        attn_scores.append(get_att_score(dec_output, enc_outputs[i]))\n",
    "\n",
    "    # Normalize scores to weights in range 0 to 1\n",
    "    return tf.reshape(tf.nn.softmax(attn_scores), [1, 1, -1])  # [1, 1, n_step]\n",
    "\n",
    "model = []\n",
    "Attention = []\n",
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    # enc_outputs : [batch_size(=1), n_step(=decoder_step), n_hidden(=128)]\n",
    "    # enc_hidden : [batch_size(=1), n_hidden(=128)]\n",
    "    enc_outputs, enc_hidden = tf.nn.dynamic_rnn(enc_cell, enc_inputs, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "\n",
    "    inputs = tf.transpose(dec_inputs, [1, 0, 2])\n",
    "    hidden = enc_hidden\n",
    "    for i in range(n_step):\n",
    "        # time_major True mean inputs shape: [max_time, batch_size, ...]\n",
    "        dec_output, hidden = tf.nn.dynamic_rnn(dec_cell, tf.expand_dims(inputs[i], 1),\n",
    "                                               initial_state=hidden, dtype=tf.float32, time_major=True)\n",
    "        attn_weights = get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "        Attention.append(tf.squeeze(attn_weights))\n",
    "\n",
    "        # matrix-matrix product of matrices [1, 1, n_step] x [1, n_step, n_hidden] = [1, 1, n_hidden]\n",
    "        context = tf.matmul(attn_weights, enc_outputs)\n",
    "        dec_output = tf.squeeze(dec_output, 0)  # [1, n_step]\n",
    "        context = tf.squeeze(context, 1)  # [1, n_hidden]\n",
    "\n",
    "        model.append(tf.matmul(tf.concat((dec_output, context), 1), out))  # [n_step, batch_size(=1), n_class]\n",
    "\n",
    "trained_attn = tf.stack([Attention[0], Attention[1], Attention[2], Attention[3], Attention[4]], 0)  # to show attention matrix\n",
    "model = tf.transpose(model, [1, 0, 2])  # model : [n_step, n_class]\n",
    "prediction = tf.argmax(model, 2)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "@tf.function\n",
    "def \n",
    "# Training and Test\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(2000):\n",
    "        input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "        _, loss, attention = sess.run([optimizer, cost, trained_attn],\n",
    "                                      feed_dict={enc_inputs: input_batch, dec_inputs: output_batch, targets: target_batch})\n",
    "\n",
    "        if (epoch + 1) % 400 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    predict_batch = [np.eye(n_class)[[word_dict[n] for n in 'P P P P P'.split()]]]\n",
    "    result = sess.run(prediction, feed_dict={enc_inputs: input_batch, dec_inputs: predict_batch})\n",
    "    print(sentences[0].split(), '->', [number_dict[n] for n in result[0]])\n",
    "\n",
    "    # Show Attention\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq(Attention)-Tensor.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
